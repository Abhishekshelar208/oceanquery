#!/usr/bin/env python3
"""
Production RAG System Test with Sentence Transformers.

Tests the complete production-ready RAG system using local embeddings.
"""

import sys
import os
import asyncio
from pathlib import Path
import time

# Add the backend src to path
backend_src = Path(__file__).parent.parent / "src"
sys.path.insert(0, str(backend_src))
os.environ['PYTHONPATH'] = str(backend_src)

async def test_production_rag_system():
    """Test the production RAG system with Sentence Transformers."""
    
    print("ğŸš€ OceanQuery Production RAG System Test")
    print("=" * 60)
    print("ğŸŒŸ Using Sentence Transformers - No API keys required!")
    print()
    
    try:
        start_time = time.time()
        
        # 1. Initialize RAG system
        print("1. Initializing production RAG system...")
        from services.rag import initialize_rag_system
        
        vector_store, knowledge_manager, rag_orchestrator = initialize_rag_system(
            embedding_model="all-MiniLM-L6-v2"  # Production model
        )
        init_time = time.time() - start_time
        print(f"   âœ… RAG system initialized in {init_time:.2f}s")
        
        # Check embedding model info
        if hasattr(vector_store.embedding_function, 'get_model_info'):
            model_info = vector_store.embedding_function.get_model_info()
            print(f"   ğŸ“Š Model: {model_info.get('model_name', 'Unknown')}")
            print(f"   ğŸ“ Dimensions: {model_info.get('embedding_dimension', 'Unknown')}")
            print(f"   ğŸ’» Device: {model_info.get('device', 'Unknown')}")
        
        # 2. Load knowledge base
        print("\n2. Loading oceanographic knowledge base...")
        load_start = time.time()
        load_results = knowledge_manager.load_oceanographic_knowledge()
        load_time = time.time() - load_start
        
        successful_loads = sum(1 for success in load_results.values() if success)
        total_collections = len(load_results)
        
        print(f"   ğŸ“š Loaded {successful_loads}/{total_collections} collections in {load_time:.2f}s")
        
        # Get collection stats
        stats = vector_store.get_collection_stats()
        total_docs = sum(s.get('document_count', 0) for s in stats.values())
        print(f"   ğŸ“Š Total documents: {total_docs}")
        
        for collection, info in stats.items():
            count = info.get('document_count', 0)
            print(f"   ğŸ“ {collection}: {count} documents")
        
        # 3. Test semantic search performance
        print("\n3. Testing semantic search performance...")
        
        search_queries = [
            {
                "query": "What is ocean temperature and how does it vary?",
                "expected_topics": ["temperature", "ocean", "variation"]
            },
            {
                "query": "How do ARGO floats measure salinity accurately?",
                "expected_topics": ["argo", "salinity", "measurement"]
            },
            {
                "query": "Explain thermocline variations in deep ocean",
                "expected_topics": ["thermocline", "deep", "variation"]
            },
            {
                "query": "Quality control methods for oceanographic data",
                "expected_topics": ["quality", "control", "data"]
            },
        ]
        
        search_times = []
        relevance_scores = []
        
        for i, test_case in enumerate(search_queries, 1):
            query = test_case["query"]
            expected = test_case["expected_topics"]
            
            print(f"\n   ğŸ” Query {i}: '{query}'")
            
            search_start = time.time()
            results = knowledge_manager.search_knowledge(
                query=query,
                max_results=5,
                min_relevance=0.3
            )
            search_time = time.time() - search_start
            search_times.append(search_time)
            
            print(f"   â±ï¸  Search time: {search_time:.3f}s")
            print(f"   ğŸ“‹ Found {len(results)} relevant documents")
            
            if results:
                top_result = results[0]
                relevance = top_result.get('relevance_score', 0)
                collection = top_result.get('collection', 'unknown')
                topic = top_result.get('metadata', {}).get('topic', 'general')
                
                relevance_scores.append(relevance)
                
                print(f"   ğŸ† Top result: {topic} from {collection}")
                print(f"   ğŸ“ˆ Relevance: {relevance:.3f}")
                
                # Show content preview
                content = top_result.get('content', '')[:120] + "..."
                print(f"   ğŸ“ Preview: {content}")
        
        # Calculate performance metrics
        avg_search_time = sum(search_times) / len(search_times) if search_times else 0
        avg_relevance = sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0
        
        print(f"\n   ğŸ“Š Performance Metrics:")
        print(f"      Average search time: {avg_search_time:.3f}s")
        print(f"      Average relevance: {avg_relevance:.3f}")
        print(f"      Minimum relevance: {min(relevance_scores):.3f}")
        print(f"      Maximum relevance: {max(relevance_scores):.3f}")
        
        # 4. Test RAG context enhancement
        print("\n4. Testing RAG context enhancement...")
        
        enhancement_queries = [
            {
                "query": "Show temperature trends in Pacific Ocean",
                "intent": {
                    "intent_type": "trend_analysis",
                    "parameters": {"location": "Pacific", "measurement": "temperature"}
                }
            },
            {
                "query": "Compare ARGO data quality between regions",
                "intent": {
                    "intent_type": "comparison",
                    "parameters": {"topic": "quality", "system": "argo"}
                }
            }
        ]
        
        for i, test_case in enumerate(enhancement_queries, 1):
            query = test_case["query"]
            intent = test_case["intent"]
            
            print(f"\n   ğŸ¯ Enhancement test {i}: '{query}'")
            
            enhance_start = time.time()
            enhanced_context = rag_orchestrator.enhance_query_with_context(
                user_query=query,
                conversation_history=None,
                query_intent=intent
            )
            enhance_time = time.time() - enhance_start
            
            status = enhanced_context.get('enhancement_status')
            knowledge_count = len(enhanced_context.get('knowledge_context', []))
            summary = enhanced_context.get('context_summary', 'No context')
            
            print(f"   â±ï¸  Enhancement time: {enhance_time:.3f}s")
            print(f"   ğŸ“ˆ Status: {status}")
            print(f"   ğŸ“š Knowledge chunks: {knowledge_count}")
            print(f"   ğŸ“ Summary: {summary}")
        
        # 5. Test conversation context
        print("\n5. Testing conversation context analysis...")
        
        conversation_history = [
            {"role": "user", "content": "Tell me about ocean temperature measurements"},
            {"role": "assistant", "content": "Ocean temperature is measured using various instruments..."},
            {"role": "user", "content": "What about salinity measurements?"},
            {"role": "assistant", "content": "Salinity is typically measured using conductivity sensors..."},
        ]
        
        context_test_query = "How do these measurements compare in accuracy?"
        
        enhanced_context = rag_orchestrator.enhance_query_with_context(
            user_query=context_test_query,
            conversation_history=conversation_history,
            query_intent={"intent_type": "comparison"}
        )
        
        conv_context = enhanced_context.get('conversation_context', {})
        print(f"   ğŸ’¬ Conversation context: {conv_context.get('has_context', False)}")
        print(f"   ğŸ”¤ Recent topics: {conv_context.get('recent_topics', [])}")
        print(f"   â° Temporal references: {conv_context.get('temporal_references', False)}")
        
        # 6. System statistics
        print("\n6. Production system statistics...")
        
        rag_stats = rag_orchestrator.get_rag_statistics()
        knowledge_stats = rag_stats.get('knowledge_base', {})
        config_stats = rag_stats.get('configuration', {})
        
        print(f"   ğŸ“Š Knowledge base:")
        print(f"      Total documents: {knowledge_stats.get('total_documents', 0)}")
        print(f"      Collections: {len(knowledge_stats.get('collections', {}))}")
        
        print(f"   âš™ï¸  Configuration:")
        print(f"      Max context tokens: {config_stats.get('max_context_tokens', 'N/A')}")
        print(f"      Relevance threshold: {config_stats.get('relevance_threshold', 'N/A')}")
        print(f"      Max chunks: {config_stats.get('max_knowledge_chunks', 'N/A')}")
        
        # 7. Memory and performance check
        print("\n7. System resources...")
        
        try:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            print(f"   ğŸ’¾ Memory usage: {memory_info.rss / 1024 / 1024:.1f} MB")
            print(f"   ğŸ”„ CPU percent: {process.cpu_percent():.1f}%")
        except ImportError:
            print("   â„¹ï¸  psutil not available for resource monitoring")
        
        total_time = time.time() - start_time
        print(f"\nğŸ“Š Overall Performance:")
        print(f"   â±ï¸  Total test time: {total_time:.2f}s")
        print(f"   ğŸš€ Average query processing: {avg_search_time:.3f}s")
        print(f"   ğŸ¯ Average relevance score: {avg_relevance:.3f}")
        
        # 8. Production readiness check
        print("\n8. Production readiness assessment...")
        
        readiness_score = 0
        max_score = 10
        
        # Check initialization time
        if init_time < 30:
            readiness_score += 2
            print("   âœ… Fast initialization (< 30s)")
        else:
            print("   âš ï¸  Slow initialization (> 30s)")
        
        # Check search performance
        if avg_search_time < 1.0:
            readiness_score += 2
            print("   âœ… Fast search performance (< 1s)")
        else:
            print("   âš ï¸  Slow search performance (> 1s)")
        
        # Check relevance quality
        if avg_relevance > 0.7:
            readiness_score += 2
            print("   âœ… High relevance quality (> 0.7)")
        else:
            print("   âš ï¸  Low relevance quality (< 0.7)")
        
        # Check knowledge loading
        if successful_loads == total_collections:
            readiness_score += 2
            print("   âœ… Complete knowledge loading")
        else:
            print("   âš ï¸  Incomplete knowledge loading")
        
        # Check error handling
        if load_results and all(isinstance(v, bool) for v in load_results.values()):
            readiness_score += 2
            print("   âœ… Robust error handling")
        else:
            print("   âš ï¸  Error handling issues")
        
        readiness_percentage = (readiness_score / max_score) * 100
        
        print(f"\nğŸ† Production Readiness Score: {readiness_score}/{max_score} ({readiness_percentage:.0f}%)")
        
        if readiness_percentage >= 80:
            print("ğŸ‰ READY FOR PRODUCTION DEPLOYMENT! ğŸš€")
        elif readiness_percentage >= 60:
            print("âš ï¸  NEEDS MINOR OPTIMIZATIONS BEFORE PRODUCTION")
        else:
            print("âŒ REQUIRES SIGNIFICANT IMPROVEMENTS")
        
        print("\nâœ¨ Production RAG System Features:")
        print("   â€¢ ğŸŒŸ No API keys required")
        print("   â€¢ ğŸ  Fully local processing")
        print("   â€¢ ğŸ“š 38+ oceanographic knowledge documents")
        print("   â€¢ ğŸ” High-quality semantic search")
        print("   â€¢ ğŸ’¬ Conversation-aware context")
        print("   â€¢ âš¡ Fast response times")
        print("   â€¢ ğŸ›¡ï¸  Production-ready reliability")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Production RAG test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Main test function."""
    print("ğŸŒŠ OceanQuery Production RAG System Test")
    print("=" * 50)
    print("Testing complete Sentence Transformers implementation")
    print()
    
    success = asyncio.run(test_production_rag_system())
    
    if success:
        print("\n" + "=" * 60)
        print("ğŸŠ PRODUCTION RAG SYSTEM IS READY!")
        print("=" * 60)
        print("âœ… Your system now has:")
        print("   â€¢ Complete offline RAG functionality")
        print("   â€¢ No external API dependencies")
        print("   â€¢ High-quality embeddings")
        print("   â€¢ Production-ready performance")
        print("   â€¢ Scalable architecture")
        print()
        print("ğŸš€ Ready for deployment and competition!")
        sys.exit(0)
    else:
        print("\nğŸ’¥ System needs attention before production use.")
        sys.exit(1)


if __name__ == "__main__":
    main()